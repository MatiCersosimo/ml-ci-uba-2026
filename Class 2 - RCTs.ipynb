{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Class 2: Randomized Controlled Trials (RCTs)\n",
        "\n",
        "- Potential Outcomes model for causal effects and the Fundamental Problem of Causal Inference\n",
        "- Data simulations. Seeds. \n",
        "- RCTs. Difference in means estimator.\n",
        "- Variance reduction. Lin's (2013) adjustment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74cda798",
      "metadata": {},
      "source": [
        "## Potential outcomes model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23e74687",
      "metadata": {},
      "source": [
        "Imagine that we run a delivery platform that mainly provides grocery delivery services. Say that we want to understand how the first delivery of a customer arriving late affects the platform's revenue. Let $W_i \\in \\{0,1\\}$ indicate whether customer $i$ received their initial delivery on time ($1$) or not ($0$) and let $Y_i \\geq 0$ indicate the revenue per customer in their first month. $W$ is usually called **treatment** variable, and $Y$ is usually referred to as the **outcome** variable.\n",
        "\n",
        "We would like to answer the question: How does the late status of the delivery ($W_i$) changing from $0$ to $1$ affect revenue from customer $i$, $Y_i$? The quantity we are interested in learning is the difference in the value of the outcome under $W_i = 1$ and under $W_i = 0$. The values of the outcome under the different levels of the variable of interest are known as **Potential Outcomes**, and are expressed as $Y_i(w_i)$ where $w_i$ is the realization of $W_i$. The difference between two potential outcomes is the **Individual Causal Effect**:     \n",
        "\n",
        "$$\\Delta_i = Y_i(1) - Y_i(0)$$\n",
        "\n",
        "In the potential outcomes model, we let the observed outcome $Y_i$ be equal to the potential outcome corresponding to the realization of $W_i$. That is, if customer $i$ received their delivery on time, we would have $Y_i = Y_i(1)$. If not, then $Y_i = Y_i(0)$. This is the key aspect of this model: potential outcomes are not directly observable. We learn them through the observed outcome $Y_i$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab03ca48",
      "metadata": {},
      "source": [
        "## Fundamental Problem of Causal Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffba2964",
      "metadata": {},
      "source": [
        "Let's go back to our main question about individual causal effects. As it stands, we claim that this question is _fundamentally_ impossible to answer. Why? Because customer's $i$ first delivery occurs once and either arrives late or not, not both. Equivalently, $Y_i$ can be equal to either $Y_i(0)$ or $Y_i(1)$, not both, which is the same to say as we can learn $Y_i(0)$ or $Y_i(1)$ through $Y_i$, but not both.\n",
        "\n",
        "Say that customer $i$ received their delivery late and their revenue per month is low, equal to $0.50$. Therefore, $w_i = 0$ and $Y_i = Y_i(0) = 0.50$. Can we claim that had they received the delivery on time, they would have led to less revenue for our platform? That is, can we claim that $Y_i(1) > 0.50$? Under this framework, it becomes evident that we cannot learn $Y_i(1)$ through direct observation if $w_i = 0$, because $w_i$ can only take one value. It might be true that having received the delivery on time might have increased revenue because of how the customer perceives the quality of the service, but the observed data is also consistent with a scenario where the customer would have churned regardless of lateness because, say, they did not receive all the items they ordered. \n",
        "\n",
        "In this model, potential outcomes under values of the variable of interest different than the one realized are called **counterfactual** outcomes, or simply **counterfactuals**. In the example above, where $w_i = 0$ and we learn $Y_i(0)$ through $Y_i$, $Y_i(1)$ is the counterfactual. To learn it through observation, we would need to be in a world scenario under which the same customer places the same order at the same point in time, and all else equal, the delivery arrives on time, that is, $w_i = 1$. This is obviously impossible, (hence the name \"counterfactual\") and this is what is known as the Fundamental Problem of Causal Inference. We cannot possibly learn individual causal effects.\n",
        "\n",
        "But that does not mean we cannot learn anything. Causal Inference is the discipline that attempts to construct credible counterfactuals that allow us to learn a variety of causal effects. In this course, we will focus on the most common, most studied, and arguably, one of the most useful quantities in the causal inference universe: the **Average Causal Effect** or **Average Treatment Effect (ATE)**.   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7664246",
      "metadata": {},
      "source": [
        "## Average Treatment Effects (ATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce79efe6",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "We concluded that we cannot learn individual causal effects. But we might still be interested in the effect of a late delivery on revenue for the average customer. Let's define the **Average treatment effect** (or **ATE**) $\\tau$ as:\n",
        "\n",
        "\\begin{align*}\n",
        "\\tau &= \\mathbb{E}[\\Delta_i] \\\\\n",
        "\\tau &= \\mathbb{E}[Y_i(1) - Y_i(0)] \\\\\n",
        "\\tau &= \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)]\n",
        "\\end{align*}\n",
        "\n",
        "Do we have a chance of learning $\\tau$? Let's say we have a sample of $n$ customers. In our sample, we will have some that received lates, and some that received orders on time. Could we extract some learnings about the average customer from analyzing the revenue per customer of these groups? We can definitely observe revenue for the average customer under the \"late\" group, and for the customer under the \"on-time\" group. Could we construct some estimator for $\\tau$ with this? An intuitive one would be computing the difference in means of the two groups. Let $n_1$ and $n_0$ be the number of customers in each group, respectively, and let $n=n_1 + n_0$. The **Difference in Means** estimator is defined as:\n",
        "\n",
        "$$\\hat{\\tau}_{DM} = \\frac{1}{n_1}\\sum_{W_i = 1} Y_i - \\frac{1}{n_0}\\sum_{W_i = 0} Y_i$$\n",
        "\n",
        "Is this a good estimator for $\\tau$? Let's find out. Using the fact that $W_i \\in \\{0,1\\}$ and standard properties of expectation, we can write:\n",
        "\n",
        "\\begin{align*}\n",
        "\\mathbb{E}[\\hat{\\tau}_{DM}] &= \\mathbb{E}\\left[\\frac{1}{n_1}\\sum_{W_i = 1} Y_i - \\frac{1}{n_0}\\sum_{W_i = 0} Y_i\\right]\\\\\n",
        "\\mathbb{E}[\\hat{\\tau}_{DM}] &= \\frac{1}{n_1}\\sum_{i}\\mathbb{E}\\left[W_iY_i\\right] - \\frac{1}{n_0}\\sum_i\\mathbb{E}\\left[(1-W_i) Y_i\\right]\\\\\n",
        "\\end{align*}\n",
        "\n",
        "And now we use the Potential Outcomes model. More precisely, we introduce a critical assumption for this model to work: the Stable Unit Treatment Values Assumption or SUTVA:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\text{(SUTVA):} \\; Y_i = Y_i(W_i), \\qquad i=1,\\ldots,n\n",
        "\\end{equation*}\n",
        "\n",
        "In plain language, SUTVA requires that potential outcomes for a unit are function of the unit's own treatment and not change under different realization of the treatment for other units (something we glossed over when introducing the framework). This is also known as the \"No interference\" assumption. In our scenario, it means that the fact that a given customer received their delivery late or not has no impact on the revenue of the other customers.      \n",
        "\n",
        "Let's continue with our estimator:\n",
        "\n",
        "\\begin{align*}\n",
        "\\mathbb{E}[\\hat{\\tau}_{DM}] &= \\frac{1}{n_1}\\sum_{i}\\mathbb{E}\\left[W_iY_i\\right] - \\frac{1}{n_0}\\sum_i\\left[(1-W_i) Y_i\\right]\\\\\n",
        "\\mathbb{E}[\\hat{\\tau}_{DM}] &= \\frac{1}{n_1}\\sum_{i}\\mathbb{E}\\left[W_iY_i(1)\\right] - \\frac{1}{n_0}\\sum_i\\mathbb{E}\\left[(1-W_i) Y_i(0)\\right]\\\\\n",
        "\\end{align*}\n",
        "\n",
        "It seems that we would need to know something about the joint distribution of $W_i$, $Y_i(1)$ and $Y_i(0)$ to compute the expectations. But what if we simply assume that $W_i$ is independent from $Y_i(1)$ and $Y_i(0)$? Then we would have:\n",
        "\n",
        "\\begin{align*}\n",
        "\\mathbb{E}[\\hat{\\tau}_{DM}] &= \\frac{1}{n_1}\\sum_{i}\\mathbb{E}\\left[W_iY_i(1)\\right] - \\frac{1}{n_0}\\sum_i\\mathbb{E}\\left[(1-W_i) Y_i(0)\\right]\\\\\n",
        "\\mathbb{E}[\\hat{\\tau}_{DM}] &= \\frac{1}{n_1}\\sum_{i}\\mathbb{E}\\left[W_i\\right]\\mathbb{E}\\left[Y_i(1)\\right] - \\frac{1}{n_0}\\sum_i\\mathbb{E}\\left[(1-W_i)\\right] \\mathbb{E}\\left[Y_i(0)\\right]\\\\\n",
        "\\end{align*}\n",
        "\n",
        "We are getting closer! Let's impose one additional assumption, that the probability of customer $i$ receiving their delivery on time is equal to the observed fraction of customers with on-time deliveries $n_1$ over the total number of observed customers $n$, for all $i$. Then:  \n",
        "\n",
        "\\begin{align*}\n",
        "\\mathbb{E}[\\hat{\\tau}_{DM}] &= \\frac{1}{n_1}\\sum_{i}\\mathbb{E}\\left[W_i\\right]\\mathbb{E}\\left[Y_i(1)\\right] - \\frac{1}{n_0}\\sum_i\\mathbb{E}\\left[(1-W_i)\\right] \\mathbb{E}\\left[Y_i(0)\\right]\\\\\n",
        "\\mathbb{E}[\\hat{\\tau}_{DM}] &= \\frac{1}{n_1}\\sum_{i}\\frac{n_1}{n}\\mathbb{E}\\left[Y_i(1)\\right] - \\frac{1}{n_0}\\sum_i 1-\\frac{n_1}{n} \\mathbb{E}\\left[Y_i(0)\\right]\\\\\n",
        "\\mathbb{E}[\\hat{\\tau}_{DM}] &= \\frac{1}{n} \\sum_{i}\\mathbb{E}\\left[Y_i(1)\\right] - \\frac{1}{n}\\sum_i  \\mathbb{E}\\left[Y_i(0)\\right]\\\\\n",
        "\\mathbb{E}[\\hat{\\tau}_{DM}] &= \\frac{1}{n} \\sum_{i}\\mathbb{E}\\left[Y_i(1) - Y_i(0)\\right]\\\\\n",
        "\\end{align*}\n",
        "\n",
        "Finally, if we assume that the potential outcomes pairs are $iid$, we get:  \n",
        "\n",
        "\\begin{align*}\n",
        "\\mathbb{E}[\\hat{\\tau}_{DM}] &= \\frac{1}{n} \\sum_{i}\\mathbb{E}\\left[Y_i(1) - Y_i(0)\\right]\\\\\n",
        "\\mathbb{E}[\\hat{\\tau}_{DM}] &= \\mathbb{E}\\left[Y_i(1) - Y_i(0)\\right]\\\\\n",
        "\\mathbb{E}[\\hat{\\tau}_{DM}] &= \\tau\\\\\n",
        "\\end{align*}\n",
        "\n",
        "Furthermore, the $iid$ assumption gets us a way to easily construct confidence intervals using the Central Limit Theorem:\n",
        "\n",
        "\n",
        "$$\\sqrt{n}(\\hat{\\tau}_{DM} - \\tau) \\implies \\mathcal{N}(0, \\mathbb{V}_{DM}), \\qquad \\mathbb{V}_{DM} = \\frac{\\mathbb{V}[Y_i(0)]}{1-\\pi} + \\frac{\\mathbb{V}[Y_i(1)]}{\\pi}$$\n",
        "\n",
        "where $\\frac{n_1}{n} \\overset{p}{\\to} \\pi$ is and $\\mathbb{V}_{DM}$ can be consistenly estimated with:\n",
        "\n",
        "$$\\hat{\\mathbb{V}}_{DM} = \\frac{n}{n_0^2} \\sum_{W_i = 0} \\left(Y_i - \\frac{1}{n_0}\\sum_{W_i = 0}Y_i\\right)^2 + \\frac{n}{n_1^2} \\sum_{W_i = 1} \\left(Y_i - \\frac{1}{n_1}\\sum_{W_i = 1}Y_i\\right)^2$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ded26d79",
      "metadata": {},
      "source": [
        "## RCTs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "961f7c9a",
      "metadata": {},
      "source": [
        "So, $\\hat{\\tau}_{DM}$ unbiased for $\\tau$ requires a number of assumptions. Two of them, SUTVA and pairs of potential outcomes being $iid$ are ones that will be carried over throughout. But the remaining assumption, independence of $W_i$ from the potential outcomes, requires more attention. Let's think through the implications in the context of our lates and revenue per customer setting. If we believe that deliveries arriving late are not related to revenue potential outcomes for users then our difference-in-means estimator is unbiased. But what if users that experience a late delivery are more likely to have a stronger need for our services and therefore a higher baseline revenue? It could be that these users would use our service more actively, ordering more items and increasing the chances of the delivery being late. If this is true, then what can't be true is $W_i$ being independent from the potential outcomes, and therefore $\\hat{\\tau}_{DM}$ is not unbiased anymore and does not **identify** the average treatment effect $\\tau$. In our scenario, the average customer who receives their deliveries on time is not a good counterfactual for the average customer who receives their deliveries late, and viceversa, so they cannot be reliably compared."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc094dd9",
      "metadata": {},
      "source": [
        "The treatment independence assumption is hard to defend in almost every situation. But there is one situation where we can have it for granted, and that is when we have direct control of the treatment assignment. In this ideal world, we can simply randomize among our customers which ones get a late delivery and which ones don't by flipping a coin for each customer. Independence of treatment from potential outcomes holds by construction and, under the other assumptions, difference-in-means is indeed a valid estimator for $\\tau$. This is known as a **Randomized Control Trial (RCT)**, or randomized experiment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e3736d8",
      "metadata": {},
      "source": [
        "Let's imagine that we have the power to randomly assign our late treatment and we run an experiment on our customer base and explore the difference in means estimator. We will simulate the following data generating process (DGP):\n",
        "\n",
        "\\begin{align*}\n",
        "i &= 1,\\ldots, n\\\\\n",
        "X_{ij} &\\overset{iid}{\\sim} \\mathcal{U}(-1, 1), \\; j \\in \\{1,2,3\\}\\\\\n",
        "W_i &\\overset{iid}{\\sim} Ber(p)\\\\\n",
        "Y_i &= \\text{exp}(X_{1i} + X_{2i}) + 0.25 W_i  \n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6cf09bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ddebdaf",
      "metadata": {},
      "source": [
        "## Variance Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8ae9d5a",
      "metadata": {},
      "source": [
        "### Regression-based adjustments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb57bf34",
      "metadata": {},
      "source": [
        "The difference in means estimator is nice because it is both simple and straight-forward. But it is not the only way to get an unbiased estimator for $\\tau$ and, in fact, other estimators strictly dominate it, essentially because they make use of other available data.\n",
        "\n",
        "Let's first establish some comparisons. It is easy to obtain $\\hat{\\tau}_{DM}$ in a regression setting, namely by fitting the following model:\n",
        "\n",
        "$$Y_i \\sim \\alpha + \\tau W_i$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a9fef1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4f7281a",
      "metadata": {},
      "source": [
        "Can we do better? The answer is yes. By adding covariates $X$ into the regression specification, we can reduce the variance of our estimator:\n",
        "\n",
        "$$Y_i \\sim \\alpha + \\tau W_i + \\beta_1 X_{1i} + \\beta_2 X_{2i}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca470923",
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "337b3580",
      "metadata": {},
      "source": [
        "But this matches our DGP, so it is expected to perform well. What if we added the wrong specification for the variable, say only $X_2$?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bd8ffef",
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0704630",
      "metadata": {},
      "source": [
        "What if we added a totally unrelated variable, say $X_3$?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec4d7fb2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc8a7b14",
      "metadata": {},
      "source": [
        "It doesn't seem we lose anything with respect to difference-in-means from adding $X_3$, so why don't we simply add all what we have? What if we added unrelated variables $Z_1$ to $Z_{20}$?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e5b36be",
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeece463",
      "metadata": {},
      "source": [
        "The results seem intuitive. Under the classical regression framework, adding relevant variables helps reducing variance of $\\hat{\\tau}_{REG}$. This is because part of the variance in the outcome is captured through the covariates. However, irrelevant variables add noise which, unless we have sufficient data, will hurt the precision of our estimates."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a3aa6c3",
      "metadata": {},
      "source": [
        "### Lin's Estimator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79247d8c",
      "metadata": {},
      "source": [
        "It seems that if the set of covariates used to estimate $\\hat{\\tau}_{REG}$ is reasonable, we can improve in terms of variance upon $\\hat{\\tau}_{DM}$. Is there a better estimator? The answer is yes under certain conditions, and it is developed in [Lin (2013)](https://arxiv.org/pdf/1208.2301). It is a very simple modification to the specification used to estimate $\\hat{\\tau}_{REG}$:\n",
        "\n",
        "$$Y_i \\sim \\alpha + \\tau W_i + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\delta_1 W_i (X_{1i} - \\bar{X}_1) + \\delta_2 W_i (X_{2i} - \\bar{X}_2)$$\n",
        "\n",
        "That is, we add an interaction term of the treatment indicator with the centered covariates. This estimate is asymptotically more efficient than $\\hat{\\tau}_{REG}$ unless either the treatment and control groups have equal sizes or the treatment effect and the covariates are  uncorrelated. \n",
        "\n",
        "Let's try it out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c6250c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "175630eb",
      "metadata": {},
      "source": [
        "In our setting, $\\hat{\\tau}_{LIN}$ does not seem to provide any advantage with respect to $\\hat{\\tau}_{REG}$. What could be happening in this case?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
